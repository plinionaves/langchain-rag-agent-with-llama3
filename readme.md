# RAG with LangChain and LLaMA3

Reliable, fully local RAG agents with LLaMA3 and LangChain.

## Installation

### Python

Create a virtual environment and install the requirements:

```bash
python -m venv .venv
pip install -r requirements.txt
```

### LLM

If you don't have ollama installed, follow this [doc](https://ollama.com/download).

And then run:

```bash
ollama pull llama3
```

## Running the project

Go to `Run and Debug` in VSCode and select `Debug App`.
